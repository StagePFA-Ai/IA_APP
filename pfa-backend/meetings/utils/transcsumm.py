# meetings/consumers.py
import json, re
from typing import List
import numpy as np
from channels.generic.websocket import AsyncWebsocketConsumer
from faster_whisper import WhisperModel
from transformers import pipeline

def _clean(s: str) -> str:
    """Nettoie le texte en supprimant les espaces multiples et en trimant"""
    return re.sub(r"\s+", " ", s or "").strip()

def _chunk(text: str, n=1800) -> List[str]:
    """D√©coupe un texte en morceaux de taille maximale n caract√®res"""
    return [text[i:i+n] for i in range(0, len(text), n)]

class _Models:
    """Classe contenant les mod√®les de ML charg√©s en m√©moire (singleton implicite)"""
    # Mod√®le de reconnaissance vocale (ASR) - Whisper
    asr = WhisperModel("small", device="cpu", compute_type="int8")  # commence petit pour tester
    
    # Mod√®les de r√©sum√© pour diff√©rentes langues
    summarizers = {
        "fr": pipeline("summarization", model="csebuetnlp/mT5_multilingual_XLSum"),
        "en": pipeline("summarization", model="facebook/bart-large-cnn"),
        "ar": pipeline("summarization", model="csebuetnlp/mT5_multilingual_XLSum"),
    }

class TranscriptionConsumer(AsyncWebsocketConsumer):
    """
    Consumer WebSocket pour la transcription en temps r√©el.
    
    Re√ßoit des buffers Float32Array (PCM mono 16 kHz) depuis le navigateur.
    Accumule, puis lance Whisper sur la partie nouvelle avec un l√©ger recouvrement.
    """
    
    # Constantes pour le traitement audio
    SR = 16000  # Sample rate (16 kHz)
    MIN_NEW_SEC = 2.0  # Seuil minimal de secondes avant traitement
    OVERLAP_SEC = 0.5  # Recouvrement entre les segments pour √©viter les coupures
    MIN_NEW_SAMPLES = int(SR * MIN_NEW_SEC)  # Seuil en samples
    OVERLAP_SAMPLES = int(SR * OVERLAP_SEC)  # Recouvrement en samples

    async def connect(self):
        """√âtablit la connexion WebSocket et initialise les variables d'√©tat"""
        await self.accept()
        self.recording = False  # √âtat d'enregistrement
        self.lang = "fr"  # Langue par d√©faut
        self.pcm = np.empty(0, dtype=np.float32)   # Tampon pour tout le flux PCM
        self.processed = 0  # Nombre de samples d√©j√† trait√©s par l'ASR
        self.collected_text: List[str] = []  # Texte transcrit accumul√©

    async def disconnect(self, code):
        """G√®re la d√©connexion WebSocket"""
        self.recording = False

    async def receive(self, text_data=None, bytes_data=None):
        """
        Re√ßoit les donn√©es du client WebSocket.
        
        Deux types de donn√©es :
        - bytes_data : donn√©es audio binaires (Float32)
        - text_data : messages de contr√¥le JSON
        """
        # --- Traitement des donn√©es audio binaires (Float32) ---
        if bytes_data and self.recording:
            try:
                # Conversion des donn√©es binaires en tableau numpy
                chunk = np.frombuffer(bytes_data, dtype=np.float32)
                if chunk.size == 0:
                    return
                
                # Concat√©nation au tampon global
                self.pcm = np.concatenate([self.pcm, chunk])

                # V√©rification s'il y a assez de nouvelles donn√©es pour traitement
                await self._flush_if_enough()
            except Exception as e:
                await self._info(f"Erreur PCM: {e}")
            return

        # --- Traitement des messages texte (JSON) ---
        if text_data:
            msg = json.loads(text_data)
            action = msg.get("action")

            # D√©marrage de la transcription
            if action == "start":
                self.recording = True
                self.lang = (msg.get("lang") or "fr").lower()
                self.pcm = np.empty(0, dtype=np.float32)
                self.processed = 0
                self.collected_text.clear()
                await self._info("üé§ Transcription d√©marr√©e")

            # Arr√™t de la transcription
            elif action == "stop":
                self.recording = False
                try:
                    # Traitement final des donn√©es restantes
                    await self._flush(final=True)
                except Exception as e:
                    await self._info(f"Erreur flush final: {e}")
                await self._info("‚èπÔ∏è Transcription arr√™t√©e")

            # Demande de r√©sum√© du texte transcrit
            elif action == "summarize":
                # Concat√©nation et nettoyage de tout le texte transcrit
                full = _clean(" ".join(self.collected_text))
                if not full:
                    return await self.send(json.dumps({"type": "summary", "message": "‚ö†Ô∏è Aucun texte √† r√©sumer"}))
                
                # S√©lection du mod√®le de r√©sum√© appropri√©
                summarizer = _Models.summarizers.get(self.lang, _Models.summarizers["fr"])
                parts = []
                
                # D√©coupage et r√©sum√© par morceaux (limitations de contexte des mod√®les)
                for ch in _chunk(full, 1800):
                    out = summarizer(ch, max_length=220, min_length=60, do_sample=False)
                    parts.append(out[0]["summary_text"])
                
                # Envoi du r√©sum√© final
                await self.send(json.dumps({"type": "summary", "message": _clean(" ".join(parts))}))

    async def _flush_if_enough(self):
        """V√©rifie s'il y a assez de nouvelles donn√©es pour lancer la transcription"""
        new = self.pcm.size - self.processed
        if new >= self.MIN_NEW_SAMPLES:
            await self._run_asr()

    async def _flush(self, final=False):
        """Force le traitement des donn√©es audio restantes"""
        if self.pcm.size > self.processed:
            await self._run_asr(final=final)

    async def _run_asr(self, final=False):
        """
        Ex√©cute la reconnaissance vocale sur les donn√©es audio accumul√©es
        
        Utilise un recouvrement pour √©viter de couper les mots en fin de segment
        """
        # Calcul du segment √† traiter avec recouvrement
        start = max(0, self.processed - self.OVERLAP_SAMPLES)
        chunk = self.pcm[start:]
        
        if chunk.size <= 0:
            return

        # Transcription avec Whisper
        segments, _ = _Models.asr.transcribe(
            chunk, language=self.lang, vad_filter=True, beam_size=1
        )
        
        # Extraction et nettoyage du texte
        text = _clean(" ".join(s.text for s in segments))
        
        if text:
            # Ajout au texte accumul√© et envoi au client
            self.collected_text.append(text)
            await self.send(json.dumps({"type": "transcription", "message": text}))

        # Mise √† jour du pointeur de traitement avec recouvrement
        self.processed = max(self.processed, self.pcm.size - self.OVERLAP_SAMPLES)
        
        # En mode final, traite tout le reste
        if final:
            self.processed = self.pcm.size

    async def _info(self, m: str):
        """Envoie un message d'information au client"""
        await self.send(json.dumps({"type": "info", "message": m}))